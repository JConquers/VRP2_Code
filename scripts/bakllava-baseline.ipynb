{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11800759,"sourceType":"datasetVersion","datasetId":7410762},{"sourceId":11802069,"sourceType":"datasetVersion","datasetId":7411640}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers accelerate bert-score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-18T01:32:40.724071Z","iopub.execute_input":"2025-05-18T01:32:40.724841Z","iopub.status.idle":"2025-05-18T01:33:59.582164Z","shell.execute_reply.started":"2025-05-18T01:32:40.724817Z","shell.execute_reply":"2025-05-18T01:33:59.581390Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\nCollecting bert-score\n  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\nRequirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.2.3)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert-score) (3.7.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (11.1.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bert-score\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\nSuccessfully installed bert-score-0.3.13 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip uninstall -y pylibcudagraph-cu12 rmm-cu12\n!pip install transformers  # Use latest version for bakLlava compatibility\n!pip install scikit-learn\n!pip install timeout-decorator  # Install timeout-decorator\n\nimport pandas as pd\nfrom transformers import AutoProcessor, LlavaForConditionalGeneration\nfrom PIL import Image\nimport torch\nfrom tqdm import tqdm\nimport gc\nfrom sklearn.metrics import precision_recall_fscore_support, accuracy_score\nimport os\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom timeout_decorator import timeout, TimeoutError  # Import timeout decorator\n\n# Load the CSV file\ncsv_path = \"/kaggle/input/dataset-curated-with-split-r/Sf/Sf_qa_data_trimmed_test_r.csv\"\npred_path = \"/kaggle/working/bakllava_vqa_predictions_new.csv\"\nmetrics_path = \"/kaggle/working/bakllava_vqa_metrics_new.csv\"\ndf = pd.read_csv(csv_path, header=None, names=[\"image_path\", \"question\", \"ground_truth\"])\n\n# Load bakLlava processor and model\nmodel_id = \"llava-hf/bakLlava-v1-hf\"\nprocessor = AutoProcessor.from_pretrained(model_id)\nmodel = LlavaForConditionalGeneration.from_pretrained(model_id, torch_dtype=torch.float16)\n\n# Move model to GPU\ndevice = torch.device(\"cuda\")\nmodel.to(device)\nmodel.eval()\n\n# List to store skipped entries\nskipped_entries = []\n\n# Function to predict answer with timeout\n@timeout(10)  # Set timeout to 10 seconds\ndef predict_answer(image_path, question):\n    try:\n        if not os.path.exists(image_path):\n            print(f\"Image not found: {image_path}\")\n            return \"\"\n        image = Image.open(image_path).convert(\"RGB\")\n\n        # Prepare the VQA prompt for bakLlava\n        prompt = f\"[INST] <image> Question: {question} Answer in one word: [/INST]\"\n        inputs = processor(text=prompt, images=image, return_tensors=\"pt\").to(device, torch.float16)\n\n        with torch.no_grad():\n            outputs = model.generate(**inputs, max_new_tokens=20)\n        predicted_answer = processor.decode(outputs[0], skip_special_tokens=True).strip()\n\n        # Extract one-word answer (post-process if needed)\n        predicted_answer = predicted_answer.split()[-1]  # Take the last word as the answer\n\n        del inputs, outputs\n        gc.collect()\n        torch.cuda.empty_cache()\n        return predicted_answer\n    except Exception as e:\n        print(f\"Error processing {image_path}: {e}\")\n        return \"\"\n\n# Resume support\nstart_idx = 0\nif os.path.exists(pred_path):\n    existing = pd.read_csv(pred_path)\n    start_idx = len(existing)\n    print(f\"Resuming from index {start_idx}\")\nelse:\n    existing = pd.DataFrame()\n\n# Lists to store predictions and ground truth\npredictions = []\nground_truths = df[\"ground_truth\"].tolist()\ny_true = []\ny_pred = []\nresults = []\n\n# Predict answers for each row\nfor idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing\"):\n    if idx < start_idx:\n        continue  # Ignore those already done\n    # if idx == 100:\n    #     break  # Ignore those already done\n    full_image_path = f\"/kaggle/input/dataset-curated-with-split-r/{row['image_path']}\"\n    question = row[\"question\"]\n    try:\n        predicted = predict_answer(full_image_path, question)\n    except TimeoutError:\n        print(f\"Timeout processing row {idx}: {full_image_path}\")\n        skipped_entries.append({\"row\": idx, \"image_path\": full_image_path, \"question\": question})\n        predicted = \"\"  # Skip this entry\n    predictions.append(predicted)\n\n    y_true.append(str(ground_truths[idx]).lower())\n    y_pred.append(str(predicted).lower())\n\n    results.append({\n        \"img_path\": full_image_path,\n        \"question\": question,\n        \"true_answer\": str(ground_truths[idx]).lower(),\n        \"predicted_answer\": str(predicted).lower()\n    })\n    if idx <= 100:\n        match = \"✅\" if y_pred[-1] == y_true[-1] else \"❌\"\n        print(f\"[{idx}] Truth: {y_true[-1]} | Predicted: {y_pred[-1]} | Match: {match}\")\n\n    # Save every 1000 or last item\n    if (idx + 1) % 1000 == 0 or (idx + 1) == len(df):\n        # Convert to DataFrame\n        chunk_df = pd.DataFrame(results)\n\n        if not os.path.exists(pred_path):\n            # Write with header if file does not exist\n            chunk_df.to_csv(pred_path, mode='w', index=False, header=True)\n        else:\n            # Append without header\n            chunk_df.to_csv(pred_path, mode='a', index=False, header=False)\n\n        # Compute metrics\n        accuracy = accuracy_score(y_true, y_pred)\n        f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n        metrics_entry = pd.DataFrame([{\"step\": idx + 1, \"accuracy\": accuracy, \"f1_score\": f1}])\n\n        if not os.path.exists(metrics_path):\n            metrics_entry.to_csv(metrics_path, mode='w', index=False, header=True)\n        else:\n            metrics_entry.to_csv(metrics_path, mode='a', index=False, header=False)\n\n        # Reset for next chunk\n        results, y_true, y_pred = [], [], []\n\n        print(f\"Checkpoint saved at index {idx + 1}\")\n\n# Save predictions\nresults_df = pd.DataFrame(results)\nresults_df.to_csv(\"bakllava_vqa_predictions.csv\", index=False)\n\n# Compute accuracy and F1 score\ncorrect = 0\ntotal = len(predictions)\npredictions_lower = [str(pred).lower() for pred in predictions]\nground_truths_lower = [str(truth).lower() for truth in ground_truths]\nfor pred, truth in zip(predictions_lower, ground_truths_lower):\n    if pred == truth:\n        correct += 1\naccuracy = (correct / total) * 100 if total > 0 else 0\n# precision, recall, f1, _ = precision_recall_fscore_support(\n#     ground_truths_lower, predictions_lower, average='macro', zero_division=0\n# )\n\n# Print results\nprint(f\"\\nTotal Questions: {total}\")\nprint(f\"Correct Predictions: {correct}\")\nprint(f\"Accuracy: {accuracy:.2f}%\")\nprint(f\"F1-Score: {((2*accuracy)/(1+accuracy)):.2f}%\")\n# print(f\"Macro Precision: {precision:.2f}\")\n# print(f\"Macro Recall: {recall:.2f}\")\n# print(f\"Macro F1 Score: {f1:.2f}\")\nprint(f\"Skipped Entries: {len(skipped_entries)}\")\nif skipped_entries:\n    print(\"\\nSkipped Entries (due to timeout):\")\n    skipped_df = pd.DataFrame(skipped_entries)\n    print(skipped_df)\n\n# Display a few examples\nresults_df = pd.DataFrame({\n    \"Image Path\": df[\"image_path\"],\n    \"Question\": df[\"question\"],\n    \"Ground Truth\": ground_truths,\n    \"Predicted\": predictions\n})\nprint(\"\\nSample Predictions:\")\nprint(results_df.head(10))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T01:34:35.895716Z","iopub.execute_input":"2025-05-18T01:34:35.896021Z","execution_failed":"2025-05-18T01:38:26.143Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Skipping pylibcudagraph-cu12 as it is not installed.\u001b[0m\u001b[33m\n\u001b[0mFound existing installation: rmm-cu12 25.2.0\nUninstalling rmm-cu12-25.2.0:\n  Successfully uninstalled rmm-cu12-25.2.0\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->scikit-learn) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\nCollecting timeout-decorator\n  Downloading timeout-decorator-0.5.0.tar.gz (4.8 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nBuilding wheels for collected packages: timeout-decorator\n  Building wheel for timeout-decorator (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for timeout-decorator: filename=timeout_decorator-0.5.0-py3-none-any.whl size=5006 sha256=69750f97a3f7ba5f6a342343fe3fe3ba07eca06bf9dca60fbf6cc1e39268713c\n  Stored in directory: /root/.cache/pip/wheels/aa/cd/d1/51736c6b95846b2613a520ce146a8f305c4016a987bc9faec7\nSuccessfully built timeout-decorator\nInstalling collected packages: timeout-decorator\nSuccessfully installed timeout-decorator-0.5.0\n","output_type":"stream"},{"name":"stderr","text":"2025-05-18 01:34:59.957697: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747532100.186509      59 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747532100.251009      59 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"processor_config.json:   0%|          | 0.00/173 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49114df3afe143cc9c6431a1f33bbf09"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"chat_template.json:   0%|          | 0.00/589 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b80bab0d1e1d481b9e80ae9d44f31ab4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/505 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"902416977bb442c9afbb98a5c366059f"}},"metadata":{}},{"name":"stderr","text":"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c240f43c97ab44faa553199745a4d929"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc5087f9508f4684b9433c935062ee36"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/3.51M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d892888a21124a02b2b51fa8d18a58ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/41.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b281fcaaf3f34583b72039bf17897cf1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/552 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fff084a42754bb3963ea16380b43e22"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.02k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7675fca579e40e586eefea65c1d7df8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/70.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f20ed5b40985443fa476a3290fece0ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0b7a97f55a54026af15ffd43f70201a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a676ec939c74ea392f83dd55bfca53f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/934M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"699aec8700994a9baa59549828e2c679"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f5857c604d5459f8ff5b6b9a7587418"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.89G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02ea438aed86410fa4f7bd15b5eda887"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8caa43f2c1d0438eaa97270c5222ffd7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/141 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a0489a335534be79d350e09943813a5"}},"metadata":{}},{"name":"stderr","text":"Processing:   0%|          | 1/11972 [00:02<8:10:52,  2.46s/it]","output_type":"stream"},{"name":"stdout","text":"[0] Truth: plastic | Predicted: [/inst] | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 2/11972 [00:03<5:05:09,  1.53s/it]","output_type":"stream"},{"name":"stdout","text":"[1] Truth: black | Predicted: [/inst] | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 3/11972 [00:04<4:12:03,  1.26s/it]","output_type":"stream"},{"name":"stdout","text":"[2] Truth: tail | Predicted: fish | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 4/11972 [00:05<3:51:59,  1.16s/it]","output_type":"stream"},{"name":"stdout","text":"[3] Truth: two | Predicted: 3 | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 5/11972 [00:06<3:45:54,  1.13s/it]","output_type":"stream"},{"name":"stdout","text":"[4] Truth: lattice | Predicted: stripes | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 6/11972 [00:07<3:33:06,  1.07s/it]","output_type":"stream"},{"name":"stdout","text":"[5] Truth: pink | Predicted: pink | Match: ✅\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 7/11972 [00:08<3:33:16,  1.07s/it]","output_type":"stream"},{"name":"stdout","text":"[6] Truth: round | Predicted: loafer | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 8/11972 [00:09<3:22:37,  1.02s/it]","output_type":"stream"},{"name":"stdout","text":"[7] Truth: chain | Predicted: [/inst] | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 9/11972 [00:10<3:14:42,  1.02it/s]","output_type":"stream"},{"name":"stdout","text":"[8] Truth: black | Predicted: [/inst] | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 10/11972 [00:11<3:13:24,  1.03it/s]","output_type":"stream"},{"name":"stdout","text":"[9] Truth: red | Predicted: red | Match: ✅\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 11/11972 [00:12<3:11:43,  1.04it/s]","output_type":"stream"},{"name":"stdout","text":"[10] Truth: love | Predicted: love | Match: ✅\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 12/11972 [00:12<3:06:26,  1.07it/s]","output_type":"stream"},{"name":"stdout","text":"[11] Truth: meow | Predicted: [/inst] | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 13/11972 [00:13<3:08:19,  1.06it/s]","output_type":"stream"},{"name":"stdout","text":"[12] Truth: lake | Predicted: mountain | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 14/11972 [00:14<3:08:27,  1.06it/s]","output_type":"stream"},{"name":"stdout","text":"[13] Truth: red | Predicted: blue | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 15/11972 [00:15<3:08:13,  1.06it/s]","output_type":"stream"},{"name":"stdout","text":"[14] Truth: white | Predicted: white | Match: ✅\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 16/11972 [00:16<3:08:49,  1.06it/s]","output_type":"stream"},{"name":"stdout","text":"[15] Truth: red | Predicted: red | Match: ✅\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 17/11972 [00:17<3:04:39,  1.08it/s]","output_type":"stream"},{"name":"stdout","text":"[16] Truth: black | Predicted: [/inst] | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 18/11972 [00:18<3:06:23,  1.07it/s]","output_type":"stream"},{"name":"stdout","text":"[17] Truth: wood | Predicted: wood | Match: ✅\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 19/11972 [00:19<3:07:42,  1.06it/s]","output_type":"stream"},{"name":"stdout","text":"[18] Truth: brown | Predicted: brown | Match: ✅\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 20/11972 [00:20<3:08:15,  1.06it/s]","output_type":"stream"},{"name":"stdout","text":"[19] Truth: red | Predicted: red | Match: ✅\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 21/11972 [00:21<3:04:46,  1.08it/s]","output_type":"stream"},{"name":"stdout","text":"[20] Truth: plastic | Predicted: [/inst] | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 22/11972 [00:22<3:10:12,  1.05it/s]","output_type":"stream"},{"name":"stdout","text":"[21] Truth: slip-on | Predicted: lace | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 23/11972 [00:23<3:08:12,  1.06it/s]","output_type":"stream"},{"name":"stdout","text":"[22] Truth: rectangle | Predicted: [/inst] | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 24/11972 [00:24<3:05:05,  1.08it/s]","output_type":"stream"},{"name":"stdout","text":"[23] Truth: multicolor | Predicted: [/inst] | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 25/11972 [00:25<3:06:38,  1.07it/s]","output_type":"stream"},{"name":"stdout","text":"[24] Truth: blue | Predicted: blue | Match: ✅\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 26/11972 [00:26<3:07:59,  1.06it/s]","output_type":"stream"},{"name":"stdout","text":"[25] Truth: white | Predicted: white | Match: ✅\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 27/11972 [00:27<3:12:42,  1.03it/s]","output_type":"stream"},{"name":"stdout","text":"[26] Truth: fabric | Predicted: foam | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 28/11972 [00:28<3:08:22,  1.06it/s]","output_type":"stream"},{"name":"stdout","text":"[27] Truth: silhouette | Predicted: [/inst] | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 29/11972 [00:28<3:05:16,  1.07it/s]","output_type":"stream"},{"name":"stdout","text":"[28] Truth: teal | Predicted: [/inst] | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 30/11972 [00:29<3:02:57,  1.09it/s]","output_type":"stream"},{"name":"stdout","text":"[29] Truth: java | Predicted: [/inst] | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 31/11972 [00:30<3:05:15,  1.07it/s]","output_type":"stream"},{"name":"stdout","text":"[30] Truth: red | Predicted: black | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 32/11972 [00:31<3:09:34,  1.05it/s]","output_type":"stream"},{"name":"stdout","text":"[31] Truth: cylindrical | Predicted: round | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 33/11972 [00:32<3:06:15,  1.07it/s]","output_type":"stream"},{"name":"stdout","text":"[32] Truth: kitten | Predicted: [/inst] | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 34/11972 [00:33<3:05:41,  1.07it/s]","output_type":"stream"},{"name":"stdout","text":"[33] Truth: bottle | Predicted: [/inst] | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 35/11972 [00:34<3:03:21,  1.09it/s]","output_type":"stream"},{"name":"stdout","text":"[34] Truth: plastic | Predicted: [/inst] | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 36/11972 [00:35<3:06:10,  1.07it/s]","output_type":"stream"},{"name":"stdout","text":"[35] Truth: pink | Predicted: pink | Match: ✅\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 37/11972 [00:36<3:04:11,  1.08it/s]","output_type":"stream"},{"name":"stdout","text":"[36] Truth: leaves | Predicted: [/inst] | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 38/11972 [00:37<3:11:06,  1.04it/s]","output_type":"stream"},{"name":"stdout","text":"[37] Truth: swirl | Predicted: spiral | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 39/11972 [00:38<3:07:40,  1.06it/s]","output_type":"stream"},{"name":"stdout","text":"[38] Truth: lighthouse | Predicted: [/inst] | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 40/11972 [00:39<3:09:35,  1.05it/s]","output_type":"stream"},{"name":"stdout","text":"[39] Truth: double | Predicted: modern | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 41/11972 [00:40<3:06:46,  1.06it/s]","output_type":"stream"},{"name":"stdout","text":"[40] Truth: plastic | Predicted: [/inst] | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 42/11972 [00:41<3:04:11,  1.08it/s]","output_type":"stream"},{"name":"stdout","text":"[41] Truth: meow | Predicted: [/inst] | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 43/11972 [00:42<3:06:26,  1.07it/s]","output_type":"stream"},{"name":"stdout","text":"[42] Truth: us | Predicted: usb | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 44/11972 [00:43<3:08:13,  1.06it/s]","output_type":"stream"},{"name":"stdout","text":"[43] Truth: white | Predicted: silver | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 45/11972 [00:44<3:09:47,  1.05it/s]","output_type":"stream"},{"name":"stdout","text":"[44] Truth: cube | Predicted: square | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 46/11972 [00:45<3:15:20,  1.02it/s]","output_type":"stream"},{"name":"stdout","text":"[45] Truth: bucket | Predicted: bucket | Match: ✅\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 47/11972 [00:46<3:19:11,  1.00s/it]","output_type":"stream"},{"name":"stdout","text":"[46] Truth: wag | Predicted: wag | Match: ✅\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 48/11972 [00:47<3:12:50,  1.03it/s]","output_type":"stream"},{"name":"stdout","text":"[47] Truth: plastic | Predicted: [/inst] | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 49/11972 [00:47<3:13:06,  1.03it/s]","output_type":"stream"},{"name":"stdout","text":"[48] Truth: capri | Predicted: long | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 50/11972 [00:49<3:17:19,  1.01it/s]","output_type":"stream"},{"name":"stdout","text":"[49] Truth: tiger | Predicted: tiger | Match: ✅\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 51/11972 [00:50<3:20:23,  1.01s/it]","output_type":"stream"},{"name":"stdout","text":"[50] Truth: motorcycle | Predicted: motorcycle | Match: ✅\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 52/11972 [00:50<3:14:23,  1.02it/s]","output_type":"stream"},{"name":"stdout","text":"[51] Truth: jar | Predicted: [/inst] | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 53/11972 [00:51<3:14:54,  1.02it/s]","output_type":"stream"},{"name":"stdout","text":"[52] Truth: black | Predicted: black | Match: ✅\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 54/11972 [00:52<3:10:54,  1.04it/s]","output_type":"stream"},{"name":"stdout","text":"[53] Truth: black | Predicted: [/inst] | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 55/11972 [00:53<3:09:43,  1.05it/s]","output_type":"stream"},{"name":"stdout","text":"[54] Truth: plastic | Predicted: [/inst] | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 56/11972 [00:54<3:07:07,  1.06it/s]","output_type":"stream"},{"name":"stdout","text":"[55] Truth: rectangular | Predicted: [/inst] | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 57/11972 [00:55<3:09:55,  1.05it/s]","output_type":"stream"},{"name":"stdout","text":"[56] Truth: black | Predicted: black | Match: ✅\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 58/11972 [00:56<3:11:32,  1.04it/s]","output_type":"stream"},{"name":"stdout","text":"[57] Truth: black | Predicted: black | Match: ✅\n","output_type":"stream"},{"name":"stderr","text":"Processing:   0%|          | 59/11972 [00:57<3:13:20,  1.03it/s]","output_type":"stream"},{"name":"stdout","text":"[58] Truth: grey | Predicted: silver | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 60/11972 [00:58<3:14:00,  1.02it/s]","output_type":"stream"},{"name":"stdout","text":"[59] Truth: white | Predicted: white | Match: ✅\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 61/11972 [00:59<3:18:50,  1.00s/it]","output_type":"stream"},{"name":"stdout","text":"[60] Truth: lace-up | Predicted: velcro | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 62/11972 [01:00<3:17:52,  1.00it/s]","output_type":"stream"},{"name":"stdout","text":"[61] Truth: black | Predicted: black | Match: ✅\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 63/11972 [01:01<3:13:15,  1.03it/s]","output_type":"stream"},{"name":"stdout","text":"[62] Truth: plastic | Predicted: [/inst] | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 64/11972 [01:02<3:18:34,  1.00s/it]","output_type":"stream"},{"name":"stdout","text":"[63] Truth: rectangular | Predicted: rectangle | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 65/11972 [01:03<3:19:34,  1.01s/it]","output_type":"stream"},{"name":"stdout","text":"[64] Truth: tan | Predicted: brown | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 66/11972 [01:04<3:13:21,  1.03it/s]","output_type":"stream"},{"name":"stdout","text":"[65] Truth: grey | Predicted: [/inst] | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 67/11972 [01:05<3:13:28,  1.03it/s]","output_type":"stream"},{"name":"stdout","text":"[66] Truth: love | Predicted: love | Match: ✅\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 68/11972 [01:06<3:09:49,  1.05it/s]","output_type":"stream"},{"name":"stdout","text":"[67] Truth: fitted | Predicted: [/inst] | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 69/11972 [01:07<3:11:44,  1.03it/s]","output_type":"stream"},{"name":"stdout","text":"[68] Truth: blue | Predicted: blue | Match: ✅\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 70/11972 [01:08<3:08:34,  1.05it/s]","output_type":"stream"},{"name":"stdout","text":"[69] Truth: silicon | Predicted: [/inst] | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 71/11972 [01:09<3:11:08,  1.04it/s]","output_type":"stream"},{"name":"stdout","text":"[70] Truth: black | Predicted: blue | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 72/11972 [01:10<3:08:34,  1.05it/s]","output_type":"stream"},{"name":"stdout","text":"[71] Truth: black | Predicted: [/inst] | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 73/11972 [01:11<3:15:27,  1.01it/s]","output_type":"stream"},{"name":"stdout","text":"[72] Truth: two | Predicted: 3 | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 74/11972 [01:12<3:11:23,  1.04it/s]","output_type":"stream"},{"name":"stdout","text":"[73] Truth: rectangular | Predicted: [/inst] | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 75/11972 [01:13<3:16:51,  1.01it/s]","output_type":"stream"},{"name":"stdout","text":"[74] Truth: four | Predicted: 3 | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 76/11972 [01:14<3:16:26,  1.01it/s]","output_type":"stream"},{"name":"stdout","text":"[75] Truth: tan | Predicted: yellow | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 77/11972 [01:15<3:12:39,  1.03it/s]","output_type":"stream"},{"name":"stdout","text":"[76] Truth: silicon | Predicted: [/inst] | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 78/11972 [01:16<3:14:21,  1.02it/s]","output_type":"stream"},{"name":"stdout","text":"[77] Truth: green | Predicted: green | Match: ✅\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 79/11972 [01:17<3:18:44,  1.00s/it]","output_type":"stream"},{"name":"stdout","text":"[78] Truth: rectangular | Predicted: rectangle | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 80/11972 [01:18<3:13:37,  1.02it/s]","output_type":"stream"},{"name":"stdout","text":"[79] Truth: pink | Predicted: [/inst] | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 81/11972 [01:19<3:14:16,  1.02it/s]","output_type":"stream"},{"name":"stdout","text":"[80] Truth: stars | Predicted: stars | Match: ✅\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 82/11972 [01:20<3:19:15,  1.01s/it]","output_type":"stream"},{"name":"stdout","text":"[81] Truth: hearts | Predicted: hearts | Match: ✅\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 83/11972 [01:21<3:18:37,  1.00s/it]","output_type":"stream"},{"name":"stdout","text":"[82] Truth: crown | Predicted: queen | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 84/11972 [01:22<3:22:32,  1.02s/it]","output_type":"stream"},{"name":"stdout","text":"[83] Truth: two | Predicted: 0 | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 85/11972 [01:23<3:17:18,  1.00it/s]","output_type":"stream"},{"name":"stdout","text":"[84] Truth: green | Predicted: [/inst] | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 86/11972 [01:24<3:17:52,  1.00it/s]","output_type":"stream"},{"name":"stdout","text":"[85] Truth: black | Predicted: black | Match: ✅\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 87/11972 [01:25<3:13:49,  1.02it/s]","output_type":"stream"},{"name":"stdout","text":"[86] Truth: rectangular | Predicted: [/inst] | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 88/11972 [01:26<3:15:56,  1.01it/s]","output_type":"stream"},{"name":"stdout","text":"[87] Truth: red | Predicted: blue | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 89/11972 [01:27<3:17:33,  1.00it/s]","output_type":"stream"},{"name":"stdout","text":"[88] Truth: pink | Predicted: pink | Match: ✅\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 90/11972 [01:28<3:18:32,  1.00s/it]","output_type":"stream"},{"name":"stdout","text":"[89] Truth: brown | Predicted: brown | Match: ✅\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 91/11972 [01:29<3:18:42,  1.00s/it]","output_type":"stream"},{"name":"stdout","text":"[90] Truth: black | Predicted: brown | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 92/11972 [01:30<3:19:03,  1.01s/it]","output_type":"stream"},{"name":"stdout","text":"[91] Truth: black | Predicted: black | Match: ✅\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 93/11972 [01:31<3:14:58,  1.02it/s]","output_type":"stream"},{"name":"stdout","text":"[92] Truth: feather | Predicted: [/inst] | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 94/11972 [01:32<3:12:32,  1.03it/s]","output_type":"stream"},{"name":"stdout","text":"[93] Truth: purple | Predicted: [/inst] | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 95/11972 [01:33<3:14:47,  1.02it/s]","output_type":"stream"},{"name":"stdout","text":"[94] Truth: teal | Predicted: blue | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 96/11972 [01:34<3:25:16,  1.04s/it]","output_type":"stream"},{"name":"stdout","text":"[95] Truth: fur | Predicted: fuzzy | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 97/11972 [01:35<3:28:47,  1.05s/it]","output_type":"stream"},{"name":"stdout","text":"[96] Truth: mesh | Predicted: plastic | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 98/11972 [01:36<3:22:05,  1.02s/it]","output_type":"stream"},{"name":"stdout","text":"[97] Truth: cloth | Predicted: [/inst] | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 99/11972 [01:37<3:25:59,  1.04s/it]","output_type":"stream"},{"name":"stdout","text":"[98] Truth: boat | Predicted: boat | Match: ✅\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 100/11972 [01:38<3:19:38,  1.01s/it]","output_type":"stream"},{"name":"stdout","text":"[99] Truth: rectangular | Predicted: [/inst] | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 101/11972 [01:39<3:16:16,  1.01it/s]","output_type":"stream"},{"name":"stdout","text":"[100] Truth: green | Predicted: [/inst] | Match: ❌\n","output_type":"stream"},{"name":"stderr","text":"Processing:   1%|          | 112/11972 [01:50<3:14:50,  1.01it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"print(len(predictions_lower))\nprint(len(ground_truths_lower))","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}